{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b20802",
   "metadata": {},
   "source": [
    "# Fixmydata tutorial: cleaning built-in datasets\n",
    "\n",
    "This notebook demonstrates how to explore and clean the bundled sample datasets using the `Fixmydata` utilities. Each section mirrors a typical data quality workflow so you can adapt the snippets to your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2040a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Install dependencies from `requirements.txt`.\n",
    "- Ensure the project root is on your Python path so `Fixmydata` can be imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95714c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Fixmydata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(ROOT))\n\u001b[0;32m     10\u001b[0m DATA_DIR \u001b[38;5;241m=\u001b[39m ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFixmydata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCleaner, DataValidator, OutlierDetector\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Fixmydata'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure project root is on the Python path\n",
    "ROOT = Path().resolve().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "DATA_DIR = ROOT / 'datasets'\n",
    "\n",
    "from Fixmydata import DataCleaner, DataValidator, OutlierDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418550e",
   "metadata": {},
   "source": [
    "## 1. Load the Titanic-style passenger data\n",
    "\n",
    "We will use `datasets/tested.csv`, which mirrors the familiar Titanic competition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb163ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_path = DATA_DIR / 'tested.csv'\n",
    "titanic_df = pd.read_csv(titanic_path)\n",
    "\n",
    "print(titanic_df.shape)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c6444",
   "metadata": {},
   "source": [
    "### Inspect missing values\n",
    "Before cleaning, it is useful to see which columns contain gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017feaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum().to_frame('missing_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664b816",
   "metadata": {},
   "source": [
    "## 2. Clean the passenger data\n",
    "We will standardize column names, fill missing numeric values with the median, fill categorical gaps with the mode, and remove duplicates. The `DataCleaner` instance keeps track of the working DataFrame internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b466a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataCleaner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaner \u001b[38;5;241m=\u001b[39m DataCleaner(titanic_df)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Normalize headers for easier downstream processing\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cleaner\u001b[38;5;241m.\u001b[39mstandardize_columns()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataCleaner' is not defined"
     ]
    }
   ],
   "source": [
    "cleaning = DataCleaner(titanic_df)\n",
    "\n",
    "# Normalize headers for easier downstream processing\n",
    "cleaning.standardize_columns()\n",
    "\n",
    "# Replace missing numeric values with medians\n",
    "cleaning.fill_missing(strategy='median', columns=['age', 'fare'])\n",
    "\n",
    "# Fill categorical gaps using the most frequent values\n",
    "cleaning.fill_missing(strategy='mode')\n",
    "\n",
    "# Drop accidental duplicate rows if any\n",
    "titanic_clean = cleaner.remove_duplicates()\n",
    "\n",
    "titanic_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeac292",
   "metadata": {},
   "source": [
    "### Validate the cleaned data\n",
    "`DataValidator` can assert common expectations. Here we ensure the DataFrame is non-empty and that passenger ages fall inside a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edcc3c4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m validator \u001b[38;5;241m=\u001b[39m DataValidator(titanic_clean)\n\u001b[0;32m      2\u001b[0m validator\u001b[38;5;241m.\u001b[39mvalidate_non_empty()\n\u001b[0;32m      3\u001b[0m validator\u001b[38;5;241m.\u001b[39mvalidate_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m90\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic_clean' is not defined"
     ]
    }
   ],
   "source": [
    "validator = DataValidator(titanic_clean)\n",
    "validator.validate_non_empty()\n",
    "validator.validate_range('age', 0, 90)\n",
    "\n",
    "titanic_clean[['age', 'fare']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d752f8",
   "metadata": {},
   "source": [
    "### Detect and remove outliers\n",
    "We can use `OutlierDetector` to filter extreme values. The IQR method is robust for skewed distributions like fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f58eab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m detector \u001b[38;5;241m=\u001b[39m OutlierDetector(titanic_clean)\n\u001b[0;32m      2\u001b[0m titanic_iqr \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39miqr_outliers()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal rows:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(titanic_clean))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic_clean' is not defined"
     ]
    }
   ],
   "source": [
    "detector = OutlierDetector(titanic_clean)\n",
    "titanic_iqr = detector.iqr_outliers()\n",
    "\n",
    "print('Original rows:', len(titanic_clean))\n",
    "print('Rows after IQR filtering:', len(titanic_iqr))\n",
    "\n",
    "titanic_iqr[['age', 'fare']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9d716",
   "metadata": {},
   "source": [
    "## 3. Explore the USA housing data\n",
    "The `USA Housing Dataset.csv` contains home sale information. The same cleaners can be applied to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43bd2700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>statezip</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-09 00:00:00</td>\n",
       "      <td>376000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1340</td>\n",
       "      <td>1384</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>9245-9249 Fremont Ave N</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA 98103</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-09 00:00:00</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3540</td>\n",
       "      <td>159430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3540</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>33001 NE 24th St</td>\n",
       "      <td>Carnation</td>\n",
       "      <td>WA 98014</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-09 00:00:00</td>\n",
       "      <td>2238888.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>7270</td>\n",
       "      <td>130017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6420</td>\n",
       "      <td>850</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>7070 270th Pl SE</td>\n",
       "      <td>Issaquah</td>\n",
       "      <td>WA 98029</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-09 00:00:00</td>\n",
       "      <td>324000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>998</td>\n",
       "      <td>904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>798</td>\n",
       "      <td>200</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>820 NW 95th St</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA 98117</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-10 00:00:00</td>\n",
       "      <td>549900.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3060</td>\n",
       "      <td>7015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1600</td>\n",
       "      <td>1460</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>10834 31st Ave SW</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA 98146</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0  2014-05-09 00:00:00   376000.0       3.0       2.00         1340      1384   \n",
       "1  2014-05-09 00:00:00   800000.0       4.0       3.25         3540    159430   \n",
       "2  2014-05-09 00:00:00  2238888.0       5.0       6.50         7270    130017   \n",
       "3  2014-05-09 00:00:00   324000.0       3.0       2.25          998       904   \n",
       "4  2014-05-10 00:00:00   549900.0       5.0       2.75         3060      7015   \n",
       "\n",
       "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
       "0     3.0           0     0          3        1340              0      2008   \n",
       "1     2.0           0     0          3        3540              0      2007   \n",
       "2     2.0           0     0          3        6420            850      2010   \n",
       "3     2.0           0     0          3         798            200      2007   \n",
       "4     1.0           0     0          5        1600           1460      1979   \n",
       "\n",
       "   yr_renovated                   street       city  statezip country  \n",
       "0             0  9245-9249 Fremont Ave N    Seattle  WA 98103     USA  \n",
       "1             0         33001 NE 24th St  Carnation  WA 98014     USA  \n",
       "2             0         7070 270th Pl SE   Issaquah  WA 98029     USA  \n",
       "3             0           820 NW 95th St    Seattle  WA 98117     USA  \n",
       "4             0        10834 31st Ave SW    Seattle  WA 98146     USA  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_path = DATA_DIR / 'USA Housing Dataset.csv'\n",
    "housing_df = pd.read_csv(housing_path)\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b4da8",
   "metadata": {},
   "source": [
    "### Clean housing records and compute quick insights\n",
    "We standardize column names, fill any numeric gaps with column means, and check the relationship between living area and sale price after removing Z-score outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4332556e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataCleaner' object has no attribute 'standardize_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m housing_cleaner \u001b[38;5;241m=\u001b[39m DataCleaner(housing_df)\n\u001b[1;32m----> 2\u001b[0m housing_cleaner\u001b[38;5;241m.\u001b[39mstandardize_columns()\n\u001b[0;32m      3\u001b[0m housing_cleaner\u001b[38;5;241m.\u001b[39mfill_missing(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m housing_base \u001b[38;5;241m=\u001b[39m housing_cleaner\u001b[38;5;241m.\u001b[39mremove_duplicates()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataCleaner' object has no attribute 'standardize_columns'"
     ]
    }
   ],
   "source": [
    "housing_cleaner = DataCleaner(housing_df)\n",
    "housing_cleaner.standardize_columns()\n",
    "housing_cleaner.fill_missing(strategy='mean')\n",
    "housing_base = housing_cleaner.remove_duplicates()\n",
    "\n",
    "housing_detector = OutlierDetector(housing_base)\n",
    "housing_no_outliers = housing_detector.z_score_outliers(threshold=3)\n",
    "\n",
    "price_sqft_corr = housing_no_outliers['price'].corr(housing_no_outliers['sqft_living'])\n",
    "print(f'Correlation between price and square footage: {price_sqft_corr:.3f}')\n",
    "housing_no_outliers[['price', 'sqft_living', 'bedrooms', 'bathrooms']].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
